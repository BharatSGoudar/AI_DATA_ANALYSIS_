{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'great_expectations.data_context' has no attribute 'DataContext'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Batch\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Initialize a new Great Expectations context\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43mge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataContext\u001b[49m()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Create a basic DataFrame using pandas (assuming you already have pandas installed)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'great_expectations.data_context' has no attribute 'DataContext'"
     ]
    }
   ],
   "source": [
    "# Activity 4: Data Quality Automation Tools\n",
    "\n",
    "# Task A: Using Great Expectations\n",
    "\n",
    "# 19. Setting Up Expectations:\n",
    "# - Install Great Expectations and set up a basic expectation suite.\n",
    "# - Validate a dataset and list unmet expectations.\n",
    "\n",
    "import great_expectations as ge\n",
    "from great_expectations.core.batch import Batch\n",
    "\n",
    "# Initialize a new Great Expectations context\n",
    "context = ge.data_context.DataContext()\n",
    "\n",
    "# Create a basic DataFrame using pandas (assuming you already have pandas installed)\n",
    "import pandas as pd\n",
    "\n",
    "# Example dataset\n",
    "data = {\n",
    "    'age': [25, 30, 35, 40, None, 50],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank'],\n",
    "    'salary': [50000, 55000, 60000, 65000, 70000, None]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert pandas DataFrame into a Great Expectations dataset\n",
    "df_ge = ge.from_pandas(df)\n",
    "\n",
    "# Create an expectation suite for this dataset\n",
    "suite = context.create_expectation_suite(\n",
    "    \"my_suite\", overwrite_existing=True\n",
    ")\n",
    "\n",
    "# Add expectations to the suite\n",
    "df_ge.expect_column_values_to_be_in_set('name', ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank'])\n",
    "df_ge.expect_column_values_to_be_in_range('age', 18, 100)\n",
    "df_ge.expect_column_values_to_not_be_null('salary')\n",
    "\n",
    "# Validate the data\n",
    "validation_results = df_ge.validate()\n",
    "\n",
    "# Print out validation results\n",
    "print(validation_results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 20. Testing for Expectation:\n",
    "# - Create expectations such as “column values must fall within a certain range.”\n",
    "# Check that the 'age' column values are between 18 and 100\n",
    "df_ge.expect_column_values_to_be_in_range('age', 18, 100)\n",
    "\n",
    "# Check that 'salary' is a positive value\n",
    "df_ge.expect_column_values_to_be_in_range('salary', 0, None)\n",
    "\n",
    "# Validate the data\n",
    "validation_results = df_ge.validate()\n",
    "\n",
    "# Output results\n",
    "print(validation_results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 21. Generating Data Docs:\n",
    "# - Automatically generate data quality documentation.\n",
    "context.build_data_docs()\n",
    "\n",
    "# Serve the docs using the built-in server\n",
    "context.open_data_docs()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task B: Using DQ Labs\n",
    "\n",
    "# 22. Tool Setup and Configuration:\n",
    "# - Download and configure DQ Labs on your local environment.\n",
    "# - Create a new data quality project.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'email': ['test@example.com', 'invalid_email', 'user@domain.org', 'hello@world.net', None],\n",
    "    'price': [10.5, None, 15.5, 12.0, 20.0],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Profiling: Check for missing values, data types, and unique values\n",
    "profiling_report = {\n",
    "    'missing_values': df.isnull().sum(),\n",
    "    'data_types': df.dtypes,\n",
    "    'unique_values': df.nunique()\n",
    "}\n",
    "\n",
    "print(profiling_report)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 23. Data Analysis Automation:\n",
    "# - Apply DQ Labs for automating data profiling and quality checks.\n",
    "\n",
    "# Task 1: Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Task 2: Check for duplicates\n",
    "duplicates = df[df.duplicated()]\n",
    "\n",
    "# Task 3: Identify outliers in the 'price' column (simple method using IQR)\n",
    "Q1 = df['price'].quantile(0.25)\n",
    "Q3 = df['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = df[(df['price'] < (Q1 - 1.5 * IQR)) | (df['price'] > (Q3 + 1.5 * IQR))]\n",
    "\n",
    "print(f\"Missing values:\\n{missing_values}\")\n",
    "print(f\"Duplicate records:\\n{duplicates}\")\n",
    "print(f\"Outliers in 'price' column:\\n{outliers}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 24. Quality Rule Creation:\n",
    "# - Create quality rules for detecting and handling duplicates or enforcing standards.\n",
    "import re\n",
    "\n",
    "# Rule 1: Check for valid email format using regex\n",
    "def is_valid_email(email):\n",
    "    pattern = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w{2,}$'\n",
    "    return bool(re.match(pattern, email))\n",
    "\n",
    "# Apply rule to the 'email' column\n",
    "df['email_valid'] = df['email'].apply(is_valid_email)\n",
    "\n",
    "# Rule 2: Check for duplicates in the 'id' column\n",
    "duplicates_by_id = df[df.duplicated(subset='id')]\n",
    "\n",
    "# Display the results\n",
    "print(f\"Valid emails:\\n{df[['email', 'email_valid']]}\")\n",
    "print(f\"Duplicate rows based on 'id':\\n{duplicates_by_id}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
