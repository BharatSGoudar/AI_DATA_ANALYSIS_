{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using AI for Anomalies Detection in Data Quality\n",
    "**Description**: Implement an AI-based approach to detect anomalies in data quality.\n",
    "\n",
    "**Steps**:\n",
    "1. Use an Anomaly Detection Algorithm:\n",
    "    - Use sklearn's Isolation Forest for anomaly detection.\n",
    "\n",
    "**Example data:**\n",
    "\n",
    "data = np.array([[25, 50000], [30, 60000], [35, 75000], [40, None], [45, 100000]])\n",
    "\n",
    "2. Integrate with Great Expectations:\n",
    "    - Generate alerts if anomalies are detected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'great_expectations.core.expectation_configuration'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IsolationForest\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgx\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpectation_configuration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExpectationConfiguration\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Step 1: Use an Anomaly Detection Algorithm (Isolation Forest)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdetect_data_quality_anomalies\u001b[39m(data):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'great_expectations.core.expectation_configuration'"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import great_expectations as gx\n",
    "from great_expectations.core.expectation_configuration import ExpectationConfiguration\n",
    "\n",
    "# Step 1: Use an Anomaly Detection Algorithm (Isolation Forest)\n",
    "\n",
    "def detect_data_quality_anomalies(data):\n",
    "    \"\"\"\n",
    "    Detects anomalies in the given data using Isolation Forest.\n",
    "\n",
    "    Args:\n",
    "        data (np.array): A 2D numpy array where each row represents a data point\n",
    "                         and columns represent features. Missing values (None)\n",
    "                         should be handled appropriately before passing.\n",
    "\n",
    "    Returns:\n",
    "        np.array: An array of predictions where 1 indicates inlier and -1 indicates outlier.\n",
    "                  Returns None if the input data is empty or has insufficient samples.\n",
    "    \"\"\"\n",
    "    if data is None or len(data) < 2:  # Isolation Forest needs at least 2 samples\n",
    "        print(\"Warning: Insufficient data to perform anomaly detection.\")\n",
    "        return None\n",
    "\n",
    "    # Handle None values by replacing them with NaN, Isolation Forest handles NaN\n",
    "    processed_data = np.array([[val if val is not None else np.nan for val in row] for row in data], dtype=float)\n",
    "\n",
    "    # Remove rows with NaN in all features (otherwise Isolation Forest might fail)\n",
    "    valid_rows_mask = ~np.all(np.isnan(processed_data), axis=1)\n",
    "    valid_data = processed_data[valid_rows_mask]\n",
    "    original_indices = np.where(valid_rows_mask)[0]\n",
    "\n",
    "    if len(valid_data) < 2:\n",
    "        print(\"Warning: Insufficient valid data points for anomaly detection after handling missing values.\")\n",
    "        return None\n",
    "\n",
    "    model = IsolationForest(random_state=42)\n",
    "    model.fit(valid_data)\n",
    "    predictions = model.predict(valid_data)\n",
    "\n",
    "    # Reconstruct predictions array to match the original data size, marking rows with all NaNs as inliers (no anomaly)\n",
    "    full_predictions = np.ones(len(data), dtype=int)\n",
    "    full_predictions[original_indices] = predictions\n",
    "\n",
    "    return full_predictions\n",
    "\n",
    "# Example data\n",
    "data = np.array([[25, 50000], [30, 60000], [35, 75000], [40, None], [45, 100000]])\n",
    "\n",
    "# Detect anomalies\n",
    "anomaly_predictions = detect_data_quality_anomalies(data)\n",
    "\n",
    "if anomaly_predictions is not None:\n",
    "    print(\"Anomaly Predictions (1: inlier, -1: outlier):\")\n",
    "    for i, prediction in enumerate(anomaly_predictions):\n",
    "        print(f\"Data Point {i+1}: {data[i]}, Prediction: {prediction}\")\n",
    "\n",
    "    # Step 2: Integrate with Great Expectations\n",
    "\n",
    "    # Create a Great Expectations Data Context (replace with your actual context setup)\n",
    "    context = gx.DataContext()\n",
    "\n",
    "    # Assume your data is in a Pandas DataFrame for easier integration with GE\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(data, columns=['age', 'salary'])\n",
    "\n",
    "    # Create a Great Expectations Datasource and DataConnector (if you haven't already)\n",
    "    # This example assumes an in-memory Pandas DataFrame\n",
    "    datasource_name = \"my_pandas_datasource\"\n",
    "    if datasource_name not in context.list_datasources()[\"name\"]:\n",
    "        context.add_pandas(name=datasource_name, batch_kwargs_list=[{\"df\": df}])\n",
    "\n",
    "    batch_kwargs = {\"datasource\": datasource_name, \"pandas_kwargs\": {}}\n",
    "    batch = context.get_batch(batch_kwargs=batch_kwargs)\n",
    "\n",
    "    expectation_suite_name = \"anomaly_detection_suite\"\n",
    "    suite = context.create_expectation_suite(\n",
    "        expectation_suite_name=expectation_suite_name, overwrite_existing=True\n",
    "    )\n",
    "\n",
    "    if anomaly_predictions is not None:\n",
    "        anomalous_indices = np.where(anomaly_predictions == -1)[0]\n",
    "\n",
    "        if len(anomalous_indices) > 0:\n",
    "            anomalous_data = df.iloc[anomalous_indices].to_dict(orient='records')\n",
    "            print(\"\\nAnomalies Detected by Isolation Forest:\")\n",
    "            for anomaly in anomalous_data:\n",
    "                print(anomaly)\n",
    "\n",
    "            # Generate a Great Expectations Expectation to check for anomalies\n",
    "            suite.add_expectation(\n",
    "                ExpectationConfiguration(\n",
    "                    expectation_type=\"expect_column_values_to_not_be_in_set\",\n",
    "                    kwargs={\n",
    "                        \"column\": \"index\",  # We'll use the index to flag anomalous rows\n",
    "                        \"value_set\": list(anomalous_indices),\n",
    "                        \"mostly\": 1.0,  # All these indices should be anomalous\n",
    "                    },\n",
    "                    meta={\n",
    "                        \"notes\": {\n",
    "                            \"format\": \"markdown\",\n",
    "                            \"content\": \"## Anomaly Detection Alert\\n\\n\"\n",
    "                            \"The following data points were identified as anomalies by the Isolation Forest algorithm.\",\n",
    "                        }\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Save the Expectation Suite\n",
    "            context.save_expectation_suite(expectation_suite=suite)\n",
    "\n",
    "            # Create a Checkpoint to run the Expectation Suite\n",
    "            checkpoint_name = \"anomaly_detection_checkpoint\"\n",
    "            checkpoint_config = {\n",
    "                \"name\": checkpoint_name,\n",
    "                \"config_version\": 1.0,\n",
    "                \"class_name\": \"SimpleCheckpoint\",\n",
    "                \"run_name_template\": \"%Y%m%d-%H%M%S-anomaly-detection\",\n",
    "                \"expectation_suite_name\": expectation_suite_name,\n",
    "                \"batch_request\": {\n",
    "                    \"datasource_name\": datasource_name,\n",
    "                    \"batch_kwargs\": batch_kwargs,\n",
    "                },\n",
    "                \"action_list\": [\n",
    "                    {\n",
    "                        \"name\": \"store_validation_result\",\n",
    "                        \"action\": {\"class_name\": \"StoreValidationResultAction\"},\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"store_evaluation_params\",\n",
    "                        \"action\": {\"class_name\": \"StoreEvaluationParametersAction\"},\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"send_slack_notification_on_validation_result\",\n",
    "                        \"action\": {\n",
    "                            \"class_name\": \"SlackNotificationAction\",\n",
    "                            \"slack_webhook\": \"YOUR_SLACK_WEBHOOK_URL\",  # Replace with your Slack webhook URL\n",
    "                            \"only_on\": \"failure\",  # Only send alert if anomalies are found (validation fails)\n",
    "                            \"message\": \"Data Quality Anomaly Detection Alert!\",\n",
    "                            \"notify_on\": \"failure\",\n",
    "                            \"renderer\": {\n",
    "                                \"class_name\": \"ValidationResultsTableRenderer\",\n",
    "                                \"styling\": {\n",
    "                                    \"default\": {\"styles\": {\"font-size\": \"0.8em\"}},\n",
    "                                    \"header\": {\"styles\": {\"font-weight\": \"bold\"}},\n",
    "                                    \"cell\": {\"styles\": {\"padding\": \"5px\"}},\n",
    "                                },\n",
    "                            },\n",
    "                        },\n",
    "                    },\n",
    "                    # Add other actions like storing to database, etc.\n",
    "                ],\n",
    "            }\n",
    "            context.add_checkpoint(**checkpoint_config)\n",
    "\n",
    "            # Run the Checkpoint\n",
    "            results = context.run_checkpoint(checkpoint_name=checkpoint_name)\n",
    "\n",
    "            if not results[\"success\"]:\n",
    "                print(\"\\nData Quality Anomaly Alert triggered!\")\n",
    "            else:\n",
    "                print(\"\\nNo data quality anomalies detected by Isolation Forest according to the Great Expectations Checkpoint.\")\n",
    "\n",
    "        else:\n",
    "            print(\"\\nNo anomalies detected by Isolation Forest.\")\n",
    "\n",
    "else:\n",
    "    print(\"Anomaly detection could not be performed due to insufficient data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
