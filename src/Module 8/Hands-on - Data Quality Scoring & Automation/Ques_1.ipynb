{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Understanding and Defining Data Quality Metrics\n",
    "**Description**: Learn how to define basic data quality metrics such as completeness, validity, and uniqueness for a simple dataset.\n",
    "\n",
    "**Steps**:\n",
    "1. Dataset: Use a CSV with columns like Name , Email , Age .\n",
    "2. Metric Definitions:\n",
    "    - Completeness: Percentage of non-null values.\n",
    "    - Validity: % of email fields containing @ .\n",
    "    - Uniqueness: Count distinct entries in the Email column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness - Name: 0.83\n",
      "Completeness - Email: 1.00\n",
      "Completeness - Age: 0.83\n",
      "Validity - Email: 0.67\n",
      "Uniqueness - Email: 6\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_completeness(series):\n",
    "    return series.count() / len(series) if len(series) > 0 else 0.0\n",
    "\n",
    "def calculate_validity_email(series):\n",
    "    valid_count = series.astype(str).str.contains('@').sum()\n",
    "    return valid_count / len(series) if len(series) > 0 else 0.0\n",
    "\n",
    "def calculate_uniqueness(series):\n",
    "    return series.nunique()\n",
    "\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', None],\n",
    "        'Email': ['alice@example.com', 'bob@example.com', 'charlie@example.com', 'david.example', 'eve@example.com', ''],\n",
    "        'Age': [25, 30, 22, None, 28, 31]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "completeness_name = calculate_completeness(df['Name'])\n",
    "completeness_email = calculate_completeness(df['Email'])\n",
    "completeness_age = calculate_completeness(df['Age'])\n",
    "\n",
    "validity_email = calculate_validity_email(df['Email'])\n",
    "\n",
    "uniqueness_email = calculate_uniqueness(df['Email'])\n",
    "\n",
    "print(f\"Completeness - Name: {completeness_name:.2f}\")\n",
    "print(f\"Completeness - Email: {completeness_email:.2f}\")\n",
    "print(f\"Completeness - Age: {completeness_age:.2f}\")\n",
    "print(f\"Validity - Email: {validity_email:.2f}\")\n",
    "print(f\"Uniqueness - Email: {uniqueness_email}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Calculating Data Quality Score\n",
    "**Description**: Aggregate multiple metrics to calculate an overall data quality score.\n",
    "\n",
    "**Steps**:\n",
    "1. Formula: Simple average of all metrics defined in Task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness - Name: 0.83\n",
      "Completeness - Email: 1.00\n",
      "Completeness - Age: 0.83\n",
      "Validity - Email: 0.67\n",
      "Uniqueness - Email: 1.00\n",
      "Overall Data Quality Score: 0.87\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_completeness(series):\n",
    "    return series.count() / len(series) if len(series) > 0 else 0.0\n",
    "\n",
    "def calculate_validity_email(series):\n",
    "    valid_count = series.astype(str).str.contains('@').sum()\n",
    "    return valid_count / len(series) if len(series) > 0 else 0.0\n",
    "\n",
    "def calculate_uniqueness(series):\n",
    "    return series.nunique() / len(series) if len(series) > 0 else 0.0\n",
    "\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', None],\n",
    "        'Email': ['alice@example.com', 'bob@example.com', 'charlie@example.com', 'david.example', 'eve@example.com', ''],\n",
    "        'Age': [25, 30, 22, None, 28, 31]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "completeness_name = calculate_completeness(df['Name'])\n",
    "completeness_email = calculate_completeness(df['Email'])\n",
    "completeness_age = calculate_completeness(df['Age'])\n",
    "\n",
    "validity_email = calculate_validity_email(df['Email'])\n",
    "\n",
    "uniqueness_email = calculate_uniqueness(df['Email'])\n",
    "\n",
    "data_quality_score = (completeness_name + completeness_email + completeness_age + validity_email + uniqueness_email) / 5\n",
    "\n",
    "print(f\"Completeness - Name: {completeness_name:.2f}\")\n",
    "print(f\"Completeness - Email: {completeness_email:.2f}\")\n",
    "print(f\"Completeness - Age: {completeness_age:.2f}\")\n",
    "print(f\"Validity - Email: {validity_email:.2f}\")\n",
    "print(f\"Uniqueness - Email: {uniqueness_email:.2f}\")\n",
    "print(f\"Overall Data Quality Score: {data_quality_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Creating Expectations for a CSV\n",
    "**Description**: Develop basic data quality expectations using Great Expectations.\n",
    "\n",
    "**Steps**:\n",
    "1. Expectation Suite\n",
    "2. Define Expectations for Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ExpectationConfiguration' from 'great_expectations.expectations.core' (/home/vscode/.local/lib/python3.10/site-packages/great_expectations/expectations/core/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mge\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExpectationConfiguration\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Step 1: Initialize the context\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ExpectationConfiguration' from 'great_expectations.expectations.core' (/home/vscode/.local/lib/python3.10/site-packages/great_expectations/expectations/core/__init__.py)"
     ]
    }
   ],
   "source": [
    "import great_expectations as ge\n",
    "from great_expectations.expectations.core import ExpectationConfiguration\n",
    "from great_expectations.expectations.dataset import Dataset\n",
    "\n",
    "# Step 1: Initialize the context\n",
    "context = ge.data_context.DataContext(\"/path/to/your/great_expectations/directory\")  # Replace with the actual path\n",
    "\n",
    "# Step 2: Create an expectation suite (if it doesn't exist)\n",
    "suite_name = \"data_quality_suite\"\n",
    "suite = context.create_expectation_suite(suite_name, overwrite_existing=True)\n",
    "\n",
    "# Step 3: Define the expectations\n",
    "expectation_1 = ExpectationConfiguration(\n",
    "    expectation_type=\"expect_column_values_to_not_be_null\", \n",
    "    kwargs={\"column\": \"customer_id\"}\n",
    ")\n",
    "\n",
    "expectation_2 = ExpectationConfiguration(\n",
    "    expectation_type=\"expect_column_values_to_be_in_set\", \n",
    "    kwargs={\"column\": \"status\", \"value_set\": [\"active\", \"inactive\"]}\n",
    ")\n",
    "\n",
    "# Add expectations to the suite\n",
    "suite.add_expectation(expectation_1)\n",
    "suite.add_expectation(expectation_2)\n",
    "\n",
    "# Step 4: Save the expectation suite\n",
    "context.save_expectation_suite(expectation_suite=suite, expectation_suite_name=suite_name)\n",
    "\n",
    "print(f\"Expectation Suite '{suite_name}' has been created and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Running and Validating Expectations\n",
    "**Description**: Run the created expectations and generate an output report.\n",
    "\n",
    "**Steps**:\n",
    "1. Validate\n",
    "2. Generate HTML Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n",
    "import great_expectations as ge\n",
    "from great_expectations.core import ExpectationConfiguration\n",
    "import os\n",
    "\n",
    "# Initialize the context\n",
    "context = ge.get_context()\n",
    "\n",
    "# Step 1: Define the batch kwargs to load data from a CSV file\n",
    "batch_kwargs = {\n",
    "    \"datasource\": \"my_csv_datasource\",  # This should be configured in your Great Expectations project\n",
    "    \"data_connector\": \"default_inferred_data_connector_name\",  # Default connector for CSV\n",
    "    \"data_asset_name\": \"your_file.csv\",  # Replace with your actual CSV file name\n",
    "}\n",
    "\n",
    "# Step 2: Get a batch of data using the batch kwargs\n",
    "batch = context.get_batch_list(batch_request=batch_kwargs)[0]\n",
    "\n",
    "# Step 3: Load the Expectation Suite that was previously created\n",
    "expectation_suite_name = \"my_csv_completeness_suite\"\n",
    "suite = context.get_expectation_suite(expectation_suite_name)\n",
    "\n",
    "# Step 4: Create a Validator\n",
    "validator = context.create_validator(\n",
    "    batch_kwargs=batch_kwargs,\n",
    "    expectation_suite=suite\n",
    ")\n",
    "\n",
    "# Step 5: Run the validation and store results\n",
    "validation_result = validator.validate()\n",
    "\n",
    "# Step 6: Generate the HTML Report for validation results\n",
    "validation_result_html = validation_result.to_json_dict()\n",
    "\n",
    "# Save the validation results as an HTML file\n",
    "output_dir = \"ge_output_reports\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, \"validation_report.html\")\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.write(validation_result_html['expectations_result']['expectations'][0]['result']['details']['formatted'])\n",
    "\n",
    "print(f\"HTML report saved at: {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Automating Data Quality Score Calculation\n",
    "**Description**: Automate the data quality score via a script that integrates with Great\n",
    "Expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n",
    "import great_expectations as ge\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Initialize Great Expectations Context\n",
    "context = ge.get_context()\n",
    "\n",
    "# Step 2: Define the Data Source and Batch Kwargs (CSV)\n",
    "batch_kwargs = {\n",
    "    \"datasource\": \"my_csv_datasource\",  # Replace with the name of your data source\n",
    "    \"data_connector\": \"default_inferred_data_connector_name\",\n",
    "    \"data_asset_name\": \"your_file.csv\",  # Replace with your actual CSV file name\n",
    "}\n",
    "\n",
    "# Step 3: Load the Data\n",
    "df = pd.read_csv(\"your_file.csv\")  # Read your CSV file into a pandas DataFrame\n",
    "batch = context.get_batch_list(batch_request=batch_kwargs)[0]  # Get the batch of data\n",
    "\n",
    "# Step 4: Create Expectation Suite (or load existing one)\n",
    "suite_name = \"data_quality_suite\"\n",
    "suite = context.create_expectation_suite(suite_name, overwrite_existing=True)\n",
    "\n",
    "# Add expectations for data quality:\n",
    "suite.add_expectation(ge.core.ExpectationConfiguration(\n",
    "    expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "    kwargs={\"column\": \"customer_id\"}  # Example: Ensure 'customer_id' is not null\n",
    "))\n",
    "\n",
    "suite.add_expectation(ge.core.ExpectationConfiguration(\n",
    "    expectation_type=\"expect_column_values_to_be_in_set\",\n",
    "    kwargs={\"column\": \"status\", \"value_set\": [\"active\", \"inactive\"]}  # Example: 'status' should be either 'active' or 'inactive'\n",
    "))\n",
    "\n",
    "# Add more expectations as necessary\n",
    "# e.g., Expecting values to be greater than a threshold for the 'age' column\n",
    "suite.add_expectation(ge.core.ExpectationConfiguration(\n",
    "    expectation_type=\"expect_column_values_to_be_greater_than\",\n",
    "    kwargs={\"column\": \"age\", \"value\": 18}  # Expecting 'age' to be greater than 18\n",
    "))\n",
    "\n",
    "# Step 5: Save the Expectation Suite\n",
    "context.save_expectation_suite(expectation_suite=suite, expectation_suite_name=suite_name)\n",
    "\n",
    "# Step 6: Validate the Data Against the Expectations\n",
    "validator = context.create_validator(\n",
    "    batch_kwargs=batch_kwargs,\n",
    "    expectation_suite=suite\n",
    ")\n",
    "\n",
    "validation_result = validator.validate()\n",
    "\n",
    "# Step 7: Calculate the Data Quality Score\n",
    "def calculate_dqi(validation_result):\n",
    "    total_expectations = len(validation_result['expectations_result']['expectations'])\n",
    "    passed_expectations = sum(1 for exp in validation_result['expectations_result']['expectations'] if exp['success'])\n",
    "    \n",
    "    if total_expectations > 0:\n",
    "        dqi = (passed_expectations / total_expectations) * 100\n",
    "    else:\n",
    "        dqi = 0  # No expectations means a score of 0\n",
    "    return dqi\n",
    "\n",
    "# Calculate the Data Quality Index (DQI)\n",
    "dqi = calculate_dqi(validation_result)\n",
    "\n",
    "# Step 8: Output the Data Quality Score\n",
    "print(f\"Data Quality Score (DQI): {dqi:.2f}%\")\n",
    "\n",
    "# Optional: Save the DQI in a log or dashboard\n",
    "# Log the score or send it to a monitoring dashboard for real-time updates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Leveraging Data Quality Metrics for Automated Data Cleaning\n",
    "**Description**: Implement a system where if data quality metrics fall below a threshold,\n",
    "automated data cleaning scripts are triggered.\n",
    "\n",
    "**Steps**:\n",
    "1. Define Cleaning Logic\n",
    "2. Integrate with Great Expectations:\n",
    "    - Use an action within the Great Expectations action list that only triggers if quality score is below a threshold, automating the cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "import great_expectations as ge\n",
    "\n",
    "# Step 1: Initialize Great Expectations Context\n",
    "context = ge.get_context()\n",
    "\n",
    "# Step 2: Load Data from CSV (or any source)\n",
    "df = pd.read_csv(\"your_file.csv\")  # Replace with your actual CSV file\n",
    "\n",
    "# Step 3: Define Data Quality Threshold\n",
    "DQI_THRESHOLD = 85  # The threshold below which cleaning is triggered\n",
    "\n",
    "# Step 4: Create or Load Expectation Suite\n",
    "suite_name = \"data_quality_suite\"\n",
    "suite = context.create_expectation_suite(suite_name, overwrite_existing=True)\n",
    "\n",
    "# Add expectations to check for missing values in key columns\n",
    "suite.add_expectation(ge.core.ExpectationConfiguration(\n",
    "    expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "    kwargs={\"column\": \"customer_id\"}\n",
    "))\n",
    "\n",
    "suite.add_expectation(ge.core.ExpectationConfiguration(\n",
    "    expectation_type=\"expect_column_values_to_be_in_set\",\n",
    "    kwargs={\"column\": \"status\", \"value_set\": [\"active\", \"inactive\"]}\n",
    "))\n",
    "\n",
    "# Add more expectations (for example: age > 18)\n",
    "suite.add_expectation(ge.core.ExpectationConfiguration(\n",
    "    expectation_type=\"expect_column_values_to_be_greater_than\",\n",
    "    kwargs={\"column\": \"age\", \"value\": 18}\n",
    "))\n",
    "\n",
    "# Save Expectation Suite\n",
    "context.save_expectation_suite(expectation_suite=suite, expectation_suite_name=suite_name)\n",
    "\n",
    "# Step 5: Run Validation on Data\n",
    "validator = context.create_validator(\n",
    "    batch_kwargs={\"datasource\": \"my_csv_datasource\", \"data_connector\": \"default_inferred_data_connector_name\", \"data_asset_name\": \"your_file.csv\"},\n",
    "    expectation_suite=suite\n",
    ")\n",
    "\n",
    "validation_result = validator.validate()\n",
    "\n",
    "# Step 6: Calculate Data Quality Score (DQI)\n",
    "def calculate_dqi(validation_result):\n",
    "    total_expectations = len(validation_result['expectations_result']['expectations'])\n",
    "    passed_expectations = sum(1 for exp in validation_result['expectations_result']['expectations'] if exp['success'])\n",
    "    \n",
    "    if total_expectations > 0:\n",
    "        dqi = (passed_expectations / total_expectations) * 100\n",
    "    else:\n",
    "        dqi = 0  # If no expectations, score is 0\n",
    "    \n",
    "    return dqi\n",
    "\n",
    "# Calculate DQI\n",
    "dqi = calculate_dqi(validation_result)\n",
    "\n",
    "# Step 7: Trigger Automated Cleaning if DQI is Below Threshold\n",
    "if dqi < DQI_THRESHOLD:\n",
    "    print(f\"Data Quality Score (DQI): {dqi:.2f}% is below the threshold. Triggering cleaning scripts...\")\n",
    "    # Call the data cleaning function if DQI is below threshold\n",
    "    df_cleaned = clean_data(df)  # Function to clean the data\n",
    "    df_cleaned.to_csv(\"your_file_cleaned.csv\", index=False)  # Save the cleaned data\n",
    "else:\n",
    "    print(f\"Data Quality Score (DQI): {dqi:.2f}% is above the threshold. No cleaning needed.\")\n",
    "\n",
    "# Step 8: Define Cleaning Logic\n",
    "def clean_data(df):\n",
    "    \"\"\"Define your data cleaning steps here.\"\"\"\n",
    "    \n",
    "    # Example: Handle missing values\n",
    "    df['customer_id'].fillna('Unknown', inplace=True)  # Fill missing customer IDs\n",
    "    df['status'].fillna('inactive', inplace=True)  # Fill missing status\n",
    "    \n",
    "    # Example: Remove duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Example: Handle outliers in age (e.g., cap ages above 100)\n",
    "    df['age'] = df['age'].apply(lambda x: 100 if x > 100 else x)\n",
    "    \n",
    "    # Add any additional cleaning logic as needed\n",
    "    return df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
